{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist data set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "general_path = r'C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations' \n",
    "os.chdir(general_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.distributions.normal import Normal\n",
    "import torch.distributions.normal as Norm\n",
    "import torch.distributions.kl as KL\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x train (60000, 784)\n",
      "shape y train 60000\n",
      "shape x test (10000, 784)\n",
      "shape y test 10000\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------\n",
    "# Change the name to create or load the data and models\n",
    "folder_data = 'Data'\n",
    "data = 'mnist'\n",
    "if not os.path.exists(os.path.join(general_path, data)):\n",
    "    print('Creating folder to save models: ', os.path.join(general_path, data))\n",
    "    os.makedirs(os.path.join(general_path, data))\n",
    "\n",
    "\n",
    "x_train = np.load(os.path.join(general_path, folder_data,'x_train.npy'))\n",
    "y_train = np.load(os.path.join(general_path, folder_data,'train_labels.npy'))\n",
    "x_test = np.load(os.path.join(general_path, folder_data,'x_test.npy'))\n",
    "y_test = np.load(os.path.join(general_path, folder_data,'test_labels.npy'))\n",
    "print('shape x train', x_train.shape)\n",
    "print('shape y train', len(y_train))\n",
    "print('shape x test', x_test.shape)\n",
    "print('shape y test', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train  1 (5923, 784)\n",
      "shape test  1 (980, 784)\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# Digit 0 to 9\n",
    "digit = 0 # None: all data\n",
    "#--------------------------------------------\n",
    "if digit == None:\n",
    "    trainY = y_train\n",
    "    testY = y_test\n",
    "    trainX = x_train\n",
    "    testX = x_test\n",
    "else:\n",
    "    idx =  np.where(y_train==digit)[0]\n",
    "    trainY, trainX = y_train[idx] ,  x_train[idx]\n",
    "    idx =  np.where(y_test==digit)[0]\n",
    "    testY, testX = y_test[idx], x_test[idx]\n",
    "\n",
    "print('shape train  1', trainX.shape)\n",
    "print('shape test  1', testX.shape)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing for semi-supervised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_semi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True masks (true binary images)\n",
    "trainYT, testYT = trainX.copy(), testX.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #name _01 params = {'p': 0.4, 'mu': 1, 'sigma': 0.25, 'size': 28}\n",
    "# # without complex noisy images\n",
    "# p = 0.4 \n",
    "# mu = 1\n",
    "# sigma = 0.25\n",
    "# size = 28\n",
    "# trainX_seq = semi_sup_preprocessing(trainX, p, mu, sigma, size)\n",
    "# testX_seq = semi_sup_preprocessing(testX, p, mu, sigma, size)\n",
    "# np.save(os.path.join(general_path, folder_data,'trainX_seq-01.npy'), trainX_seq)\n",
    "# np.save(os.path.join(general_path, folder_data,'testX_seq-01.npy'), testX_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y_train = np.load(os.path.join(general_path, folder_data,'trainX_seq-01.npy'), allow_pickle=True)\n",
    "x_y_test = np.load(os.path.join(general_path, folder_data,'testX_seq-01.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of inputs for the model\n",
    "idx = 1180\n",
    "plt.imshow(x_y_train[idx][0], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(x_y_train[idx][1], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(trainYT[idx], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " (seq, batch, elem)\n",
    "[time, batch_size, x_dim]\n",
    "x_[t] = [batch_size, x_dim]\n",
    "We take several observations at time t\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi supervised models\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Seq_Image(Dataset):\n",
    "    '''\n",
    "    Images for the semi-supervised model\n",
    "    '''\n",
    "    def __init__(self, image_list, image_shape, transforms = None):\n",
    "        # store the image and mask file\n",
    "        self.image_list = image_list # [x image, y mask]\n",
    "        self.transforms = transforms\n",
    "        self.image_shape =  image_shape\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # grab the image path from the current index    \n",
    "        image  = self.image_list[idx][0].reshape(self.image_shape)\n",
    "        mask = self.image_list[idx][1].reshape(self.image_shape)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        mask = torch.tensor(mask, dtype=torch.long) \n",
    "\n",
    "       # check to see if we are applying any transformations\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX_seq a list of [x, y_missing] where x is the noisy image and y_missing is the image with missing labels\n",
    "x_y_train = np.load(os.path.join(general_path, folder_data,'trainX_seq-01.npy'), allow_pickle=True)\n",
    "x_y_test = np.load(os.path.join(general_path, folder_data,'testX_seq-01.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Seq_Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-4ef4961792f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeq_Image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_y_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Here we use batch size 1 because we want to have the same size of the input for the model and get a dice score por each image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Seq_Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# batch_sz = 1\n",
    "# size = 28\n",
    "\n",
    "# dataset = Seq_Image(x_y_train, (size*size,1))\n",
    "# dataset_test = Seq_Image(x_y_test, (size*size,1))\n",
    "\n",
    "# print   (dataset.shape)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset,batch_sz,shuffle=False)\n",
    "# # Here we use batch size 1 because we want to have the same size of the input for the model and get a dice score por each image\n",
    "# test_loader = torch.utils.data.DataLoader(dataset_test,batch_sz,shuffle=False)\n",
    "\n",
    "# for batch_idx, datos in enumerate(train_loader):\n",
    "#     x, y = datos\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "\n",
    "#     print(x.shape), print(y.shape)\n",
    "# # for batch_idx, datos in enumerate(train_loader):\n",
    "# #     x, y = datos\n",
    "# #     x, y = x.to(device), y.to(device)\n",
    "# #     x = x.transpose(0, 1).unsqueeze(2)\n",
    "# #     y = y.transpose(0, 1).unsqueeze(2)\n",
    "# #     print(x.shape), print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(train_loader, epoch, model, optimizer, batch_sz, clip, print_every,device):\n",
    "#     '''\n",
    "#     This function trains the model for one epoch\n",
    "#     Inputs:\n",
    "#         train_loader: data loader for the training set\n",
    "#         epoch: current epoch\n",
    "#         model: model to train\n",
    "#         optimizer: optimizer to use\n",
    "#         batch_sz: batch size\n",
    "#         clip: gradient clipping\n",
    "#         print_every: print every n batches\n",
    "#         device: cpu or gpu\n",
    "#     Outputs:\n",
    "#         train_loss: loss for the training set\n",
    "#     '''\n",
    "#     train_loss = 0\n",
    "#     for batch_idx, datos in enumerate(train_loader):\n",
    "#         x, y = datos\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "#         x = x.transpose(0, 1).unsqueeze(2)\n",
    "#         y = y.transpose(0, 1).unsqueeze(2)\n",
    "            \n",
    "#         #forward + backward + optimize\n",
    "#         optimizer.zero_grad()\n",
    "    \n",
    "#         kld_loss_l, rec_loss_l, y_loss_l, kld_loss_u, rec_loss_u, y_loss_u = model(x,y)\n",
    "#         loss_l = kld_loss_l + rec_loss_l + y_loss_l\n",
    "#         loss_u = kld_loss_u + rec_loss_u + y_loss_u\n",
    "#         loss = loss_l + loss_u\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         #printing\n",
    "#         if batch_idx % print_every == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t  Loss Labeled: {:.6f} \\t Loss Unlabeled: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(datos), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader),\n",
    "#                 loss_l.item()/batch_sz,\n",
    "#                 loss_u.item()/batch_sz))     \n",
    "#             print('\\n kdl_loss_l: {:.4f} \\t rec_loss_l: {:.4f} \\t y_loss_l: {:.4f}'.format(kld_loss_l.item()/batch_sz, rec_loss_l.item()/batch_sz, y_loss_l.item()/batch_sz))\n",
    "#             print('\\n kdl_loss_u: {:.4f} \\t rec_loss_u: {:.4f} \\t y_loss_u: {:.4f}'.format(kld_loss_u.item()/batch_sz, rec_loss_u.item()/batch_sz, y_loss_u.item()/batch_sz))\n",
    "#         train_loss += loss.item()\n",
    "        \n",
    "#     print('')\n",
    "#     print('Train> Epoch: {} average -ELBO: {:.4f}'.format(epoch, train_loss/ len(train_loader.dataset)))\n",
    "#     return train_loss/ len(train_loader.dataset)\n",
    "\n",
    "\n",
    "# def test(test_loader, model):\n",
    "#     \"\"\"uses test data to evaluate\n",
    "#     likelihood of the model\"\"\"\n",
    "#     test_loss = 0\n",
    "#     Label = 0\n",
    "#     Unlabel = 0\n",
    "#     for i, datos in enumerate(test_loader):\n",
    "#         x, y = datos\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "#         x = x.transpose(0, 1).unsqueeze(2)\n",
    "#         y = y.transpose(0, 1).unsqueeze(2)\n",
    "\n",
    "#         kld_loss_l, rec_loss_l, y_loss_l, kld_loss_u, rec_loss_u, y_loss_u = model(x,y)\n",
    "#         loss_l = kld_loss_l + rec_loss_l + y_loss_l\n",
    "#         loss_u = kld_loss_u + rec_loss_u + y_loss_u\n",
    "#         loss = loss_l + loss_u\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "#         optimizer.step()\n",
    "\n",
    "#         test_loss += Label + Unlabel\n",
    "        \n",
    "#     print('Test Loss:  Loss Labeled: {:.6f} \\t Loss Unlabeled: {:.6f}'.format(\n",
    "#         Label/len(test_loader.dataset),\n",
    "#         Unlabel/len(test_loader.dataset)))     \n",
    "    \n",
    "#     return (test_loss)/len(test_loader.dataset)\n",
    "    \n",
    "\n",
    "# def run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save_model, n_epochs ,print_every, device,save_every=5):\n",
    "#     train_LOSS = []\n",
    "#     test_LOSS = []\n",
    "#     path_save = os.path.join(path_save_model, model.__class__.__name__.casefold() +'_state_')\n",
    "#     print('The model is saved in this path', os.path.join(path_save_model, model.__class__.__name__.casefold()))\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "#         #training + testing\n",
    "#         LOSS  = train(train_loader, epoch, model, optimizer, batch_sz, clip, print_every,device)\n",
    "#         LOSS_T = test(test_loader, model)\n",
    "        \n",
    "#         train_LOSS.append(LOSS)\n",
    "#         test_LOSS.append(LOSS_T)\n",
    "        \n",
    "#         #saving model\n",
    "#         if epoch % save_every == 0:\n",
    "#             fn = path_save+str(epoch)+'.pth'\n",
    "#             torch.save({\n",
    "#                         'epoch': epoch,\n",
    "#                         'model_state_dict': model.state_dict(),\n",
    "#                         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                         'loss': LOSS,\n",
    "#                         }, fn)\n",
    "#             #torch.save(model.state_dict(), fn)\n",
    "#             print('Saved model to '+fn)\n",
    "#         if epoch % print_every == 0:\n",
    "#             np.save(path_save+'train_'+str(epoch)+'.npy', train_LOSS)\n",
    "#             np.save(path_save+'val_'+str(epoch)+'.npy', test_LOSS)\n",
    "            \n",
    "#     return train_LOSS, test_LOSS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_seq(x, y,model,optimizer,clip, path_save_model, n_epochs , device,save_every=5):\n",
    "    train_LOSS = []\n",
    "    path_save = os.path.join(path_save_model, model.__class__.__name__.casefold() +'_state_')\n",
    "    print('The model is saved in this path', os.path.join(path_save_model, model.__class__.__name__.casefold()))\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        #training \n",
    "        kld_loss_l, rec_loss_l, y_loss_l, kld_loss_u, rec_loss_u, y_loss_u = model(x,y)\n",
    "        loss_l = kld_loss_l + rec_loss_l + y_loss_l\n",
    "        loss_u = kld_loss_u + rec_loss_u + y_loss_u        \n",
    "        loss = loss_l + loss_u\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        train_LOSS.append(loss.item())\n",
    "        \n",
    "        #saving model\n",
    "        if epoch % save_every == 0:\n",
    "            print('Loss Labeled: {:.6f} \\t Loss Unlabeled: {:.6f}'.format(\n",
    "                    loss_l.item(), loss_u.item()))     \n",
    "            print('\\n kdl_loss_l: {:.4f} \\t rec_loss_l: {:.4f} \\t y_loss_l: {:.4f}'.format(kld_loss_l.item(), rec_loss_l.item(), y_loss_l.item()))\n",
    "            print('\\n kdl_loss_u: {:.4f} \\t rec_loss_u: {:.4f} \\t y_loss_u: {:.4f}'.format(kld_loss_u.item(), rec_loss_u.item(), y_loss_u.item()))\n",
    "    \n",
    "            fn = path_save+str(epoch)+'.pth'\n",
    "            torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': LOSS,\n",
    "                        }, fn)\n",
    "            #torch.save(model.state_dict(), fn)\n",
    "            print('Saved model to '+fn)\n",
    "            np.save(path_save+'train_'+str(epoch)+'.npy', train_LOSS)\n",
    "            \n",
    "    return train_LOSS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 1\n",
    "z_dim = 25\n",
    "h_dim = 20\n",
    "y_dim = 1\n",
    "n_layers = 1\n",
    "bias=False\n",
    "\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "Soft_threshold = nn.Sigmoid()\n",
    "\n",
    "# Prior p(z_t | y_t, h_{t-1}) = N (μt, σt)\n",
    "prior_z = nn.Sequential( nn.Linear(h_dim + y_dim, h_dim),\n",
    "                            nn.ReLU())\n",
    "\n",
    "prior_z_mean = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "prior_z_std = nn.Sequential( nn.Linear (h_dim, z_dim), \n",
    "                            nn.Softplus())\n",
    "\n",
    "# Prior p(y_t | h_{t-1}) = Cat (θt) \n",
    "# In this case, we use a linear layer to predict the logits of the categorical distribution\n",
    "# We will use the sigmoid function to ensure that the logits are positive and only two classes\n",
    "# it means a Bernoulli distribution.\n",
    "prior_y = nn.Sequential( nn.Linear(h_dim, h_dim ),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(h_dim , h_dim ),\n",
    "                        nn.ReLU())\n",
    "\n",
    "prior_y_proba = nn.Sequential(nn.Linear(h_dim, h_dim ),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(h_dim, y_dim),\n",
    "                                nn.Sigmoid())\n",
    "\n",
    "# q(y_t | x_t, h_{t-1}) = Cat (θt)\n",
    "q_y = nn.Sequential( nn.Linear(x_dim + h_dim, h_dim ),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(h_dim , h_dim ),\n",
    "                        nn.ReLU())\n",
    "\n",
    "q_y_proba = nn.Sequential(nn.Linear(h_dim, h_dim ),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(h_dim, y_dim),\n",
    "                                nn.Sigmoid())\n",
    "\n",
    "\n",
    "# Encoder\n",
    "# q(z_t | x_t, y_t, h_{t-1}) = N (μt, σt)\n",
    "enc = nn.Sequential( nn.Linear(h_dim + x_dim + y_dim, h_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(h_dim, h_dim),\n",
    "                        nn.ReLU())\n",
    "\n",
    "enc_mean = nn.Linear(h_dim, z_dim)\n",
    "enc_std = nn.Sequential( nn.Linear (h_dim, z_dim), \n",
    "                            nn.Softplus())\n",
    "\n",
    "# Decoder\n",
    "# p(x_t | z_t, y_t, h_{t-1}) = N (μt, σt)\n",
    "dec = nn.Sequential( nn.Linear(h_dim + z_dim + y_dim, h_dim),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(h_dim, h_dim),\n",
    "                        nn.ReLU())\n",
    "\n",
    "dec_mean = nn.Linear(h_dim, x_dim)\n",
    "dec_std = nn.Sequential( nn.Linear (h_dim, x_dim), \n",
    "                            nn.Softplus())\n",
    "# Recurrence\n",
    "# h_t = f(h_{t-1}, x_t, y_t, z_t)\n",
    "# Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "rnn = nn.RNNCell( x_dim + z_dim + y_dim, h_dim, bias,nonlinearity='tanh')#nn.GRU( h_dim + x_dim + z_dim + y_dim , h_dim, n_layers)\n",
    "# summary(prior_z)\n",
    "# summary(prior_z_mean)\n",
    "# summary(prior_z_std)\n",
    "\n",
    "def _nll_ber( mean, x):\n",
    "        nll_loss = F.binary_cross_entropy(mean, x, reduction='sum')\n",
    "        return nll_loss\n",
    "    \n",
    "def _rec_gauss( x, mean, std):\n",
    "    rec_loss = torch.sum(0.5 * torch.log(2 * np.pi * std**2) + (x - mean)**2 / (2 * std**2))\n",
    "    return rec_loss\n",
    "\n",
    "def _kld_gauss( mean_1, std_1, mean_2, std_2):\n",
    "    norm_dis2 = Norm.Normal(mean_2, std_2)\n",
    "    norm_dis1 = Norm.Normal(mean_1, std_1)\n",
    "    kl_loss = torch.sum(KL.kl_divergence(norm_dis1, norm_dis2))\n",
    "    return    kl_loss\n",
    "\n",
    "def _kld_cat( q, p):\n",
    "    kl_loss = torch.sum(q * torch.log(q/p)+ (1-q) * torch.log((1-q)/(1-p)))\n",
    "    return kl_loss\n",
    "def _reparameterized_sample( mean, std):\n",
    "    \"\"\"using std to sample\"\"\"\n",
    "    eps = torch.FloatTensor(std.size()).normal_()\n",
    "    #eps = Variable(eps)\n",
    "    return eps.mul(std).add_(mean)\n",
    "\n",
    "def _reparameterized_sample_Gumbell( mean):\n",
    "    \"\"\"using std to sample\"\"\"\n",
    "    eps = torch.rand(mean.size())  #torch.FloatTensor(mean.size()).uniform()\n",
    "    #eps = Variable(eps)\n",
    "    value = torch.log(eps) - torch.log(1-eps) + torch.log(mean) - torch.log(1-mean)\n",
    "    return Soft_threshold(value)\n",
    "\n",
    "def encoder( x, y, h):\n",
    "    input_enc = torch.cat([x, y, h], 0)\n",
    "    enc_v = enc(input_enc)\n",
    "    enc_mean_v = enc_mean(enc_v)\n",
    "    enc_std_v = enc_std(enc_v)\n",
    "    return enc_mean_v, enc_std_v\n",
    "\n",
    "def decoder( z, y, h):\n",
    "    input_dec = torch.cat([z, y, h], 0)\n",
    "    dec_ = dec(input_dec)\n",
    "    dec_mean_ = dec_mean(dec_)\n",
    "    dec_std_ = dec_std(dec_)\n",
    "    return dec_mean_, dec_std_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([784, 1])\n",
      "y:  torch.Size([784, 1])\n"
     ]
    }
   ],
   "source": [
    "x_y_train = np.load(os.path.join(general_path, folder_data,'trainX_seq-01.npy'), allow_pickle=True)\n",
    "x_y_test = np.load(os.path.join(general_path, folder_data,'testX_seq-01.npy'), allow_pickle=True)\n",
    "\n",
    "idex = 50\n",
    "x  = x_y_train[idx][0].reshape((size*size,1))\n",
    "y = x_y_train[idx][1].reshape((size*size,1))\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long) \n",
    "h_t = torch.zeros(1, h_dim)\n",
    "print('x: ', x.size())\n",
    "print('y: ', y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([784, 1])\n",
      "y:  torch.Size([784, 1])\n",
      "h_t:  torch.Size([20])\n",
      "p_yt:  torch.Size([1])\n",
      "y_t :  torch.Size([1]) tensor([-1])\n",
      "q_yt:  torch.Size([1])\n",
      "input_pz:  torch.Size([21])\n",
      "prior_zt:  torch.Size([20])\n",
      "prior_zt_mean:  torch.Size([25])\n",
      "prior_zt_std:  torch.Size([25])\n",
      "enc_mean:  torch.Size([25])\n",
      "enc_std:  torch.Size([25])\n",
      "z_t:  torch.Size([25])\n",
      "kld_loss_l:  tensor(1.4692, grad_fn=<SumBackward0>)\n",
      "rec_loss_l:  tensor(0.5937, grad_fn=<SumBackward0>)\n",
      "y_loss_u:  tensor(0.0012, grad_fn=<SumBackward0>)\n",
      "rnn_input:  torch.Size([1, 27])\n",
      "h_t:  torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "h_t = torch.zeros(h_dim)\n",
    "print('x: ', x.size())\n",
    "print('y: ', y.size())\n",
    "print('h_t: ', h_t.size())\n",
    "\n",
    "rnn = nn.RNNCell( x_dim + z_dim + y_dim, h_dim, bias,nonlinearity='tanh')#nn.GRU( h_dim + x_dim + z_dim + y_dim , h_dim, n_layers)\n",
    "\n",
    "t = 548\n",
    "y[t] = -1\n",
    "p_yt = prior_y_proba(prior_y(h_t))\n",
    "print('p_yt: ', p_yt.shape)\n",
    "print('y_t : ', y[t].shape, y[t])\n",
    "if y[t] == -1:\n",
    "    q_yt = q_y_proba(q_y( torch.cat([x[t], h_t], 0)))\n",
    "    print('q_yt: ', q_yt.shape)\n",
    "    #  # Sample y_t ~ q(y_t | x_t, h_{t-1})\n",
    "    y_t = _reparameterized_sample_Gumbell(q_yt)\n",
    "    y[t] = y_t\n",
    "    \n",
    "    input_pz =  torch.cat([y[t], h_t], 0)\n",
    "    print('input_pz: ', input_pz.shape)\n",
    "    prior_zt = prior_z(input_pz)\n",
    "    print('prior_zt: ', prior_zt.shape)\n",
    "    prior_zt_mean = prior_z_mean(prior_zt)\n",
    "    print('prior_zt_mean: ', prior_zt_mean.shape)\n",
    "    prior_zt_std = prior_z_std(prior_zt)\n",
    "    print('prior_zt_std: ', prior_zt_std.shape)\n",
    "    # # Encoder q(z_t | x_t, y_t, h_{t-1})\n",
    "    enc_mean_v, enc_std_v = encoder(x[t], y[t], h_t)\n",
    "    print('enc_mean: ', enc_mean_v.shape)\n",
    "    print('enc_std: ', enc_std_v.shape)\n",
    "    z_t = _reparameterized_sample(enc_mean_v, enc_std_v)\n",
    "    print('z_t: ', z_t.shape)\n",
    "    # # Decoder p(x_t | z_t, y_t, h_{t-1})\n",
    "    dec_mean_, dec_std_ = decoder(z_t, y[t], h_t)\n",
    "    # # Loss\n",
    "    kld_loss_l = _kld_gauss(enc_mean_v, enc_std_v, prior_zt_mean, prior_zt_std)\n",
    "    rec_loss_l = _rec_gauss(x[t], dec_mean_, dec_std_)\n",
    "    print('kld_loss_l: ', kld_loss_l)\n",
    "    print('rec_loss_l: ', rec_loss_l)\n",
    "    y_loss_u = _kld_cat(p_yt, q_yt)\n",
    "    print('y_loss_u: ', y_loss_u)\n",
    "    # y_loss_l = _nll_ber(p_yt, y[t].float())\n",
    "    # print('y_loss_l: ', y_loss_l)\n",
    "    rnn_input = torch.cat([y[t], z_t, x[t-1]], 0)[None, :]\n",
    "    print('rnn_input: ', rnn_input.size())\n",
    "    print('h_t: ', h_t.unsqueeze(0).size())\n",
    "    # h_t = torch.zeros(h_dim)\n",
    "    h_t = rnn(rnn_input, h_t[None,:])\n",
    "    \n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual path to save our models for mnist is C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\mnist \n"
     ]
    }
   ],
   "source": [
    "x_dim = 1\n",
    "y_dim = 1\n",
    "\n",
    "# Dimension of latent variables\n",
    "z_dim = 10\n",
    "h_dim = 20\n",
    "n_samples = 0\n",
    "n_layers = 1\n",
    "\n",
    "# Model settings\n",
    "learning_rate = 0.003  #0.001\n",
    "weight_decay_ = 1e-4\n",
    "n_layers =  1\n",
    "n_epochs = 100\n",
    "clip = 10\n",
    "#--------------------------------------------\n",
    "# Manual seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "#--------------------------------------------\n",
    "# Print settings\n",
    "print_every = 100\n",
    "#--------------------------------------------\n",
    "# Save models\n",
    "save_every = 5\n",
    "path_save = os.path.join(general_path, data)\n",
    "print(f'Actual path to save our models for {data} is {path_save} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.special import logsumexp\n",
    "import torch.distributions.normal as Norm\n",
    "import torch.distributions.kl as KL\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "import math\n",
    "EPS = torch.finfo(torch.float).eps \n",
    "c = - 0.5 * math.log(2*math.pi)\n",
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, x_dim, z_dim, h_dim, n_layers, y_dim, device, n_samples, bias = False):\n",
    "        super(SeqModel, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.device = device\n",
    "        self.y_dim = y_dim\n",
    "        self.n_samples = n_samples\n",
    "        self.Soft_threshold = nn.Sigmoid()\n",
    "\n",
    "        # Prior p(z_t | y_t, h_{t-1}) = N (μt, σt)\n",
    "        self.prior_z = nn.Sequential( nn.Linear(self.h_dim + self.y_dim, self.h_dim),\n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.prior_z_mean = nn.Linear(self.h_dim, self.z_dim)\n",
    "        \n",
    "        self.prior_z_std = nn.Sequential( nn.Linear (self.h_dim, self.z_dim), \n",
    "                                    nn.Softplus())\n",
    "        \n",
    "        # Prior p(y_t | h_{t-1}) = Cat (θt) \n",
    "        # In this case, we use a linear layer to predict the logits of the categorical distribution\n",
    "        # We will use the sigmoid function to ensure that the logits are positive and only two classes\n",
    "        # it means a Bernoulli distribution.\n",
    "        self.prior_y = nn.Sequential( nn.Linear(self.h_dim, self.h_dim ),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(self.h_dim , self.h_dim ),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.prior_y_proba = nn.Sequential(nn.Linear(self.h_dim, self.h_dim ),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(self.h_dim, self.y_dim),\n",
    "                                      nn.Sigmoid())\n",
    "        \n",
    "        # q(y_t | x_t, h_{t-1}) = Cat (θt)\n",
    "        self.q_y = nn.Sequential( nn.Linear(self.x_dim + self.h_dim, self.h_dim ),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(self.h_dim , self.h_dim ),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.q_y_proba = nn.Sequential(nn.Linear(self.h_dim, self.h_dim ),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(self.h_dim, self.y_dim),\n",
    "                                      nn.Sigmoid())\n",
    "\n",
    "        \n",
    "        # Encoder\n",
    "        # q(z_t | x_t, y_t, h_{t-1}) = N (μt, σt)\n",
    "        self.enc = nn.Sequential( nn.Linear(self.h_dim + self.x_dim + self.y_dim, self.h_dim),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(self.h_dim, self.h_dim),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.enc_mean = nn.Linear(self.h_dim, self.z_dim)\n",
    "        self.enc_std = nn.Sequential( nn.Linear (self.h_dim, self.z_dim), \n",
    "                                    nn.Softplus())\n",
    "        \n",
    "        # Decoder\n",
    "        # p(x_t | z_t, y_t, h_{t-1}) = N (μt, σt)\n",
    "        self.dec = nn.Sequential( nn.Linear(self.h_dim + self.z_dim + self.y_dim, self.h_dim),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(self.h_dim, self.h_dim),\n",
    "                                nn.ReLU())\n",
    "        \n",
    "        self.dec_mean = nn.Linear(self.h_dim, self.x_dim)\n",
    "        self.dec_std = nn.Sequential( nn.Linear (self.h_dim, self.x_dim), \n",
    "                                    nn.Softplus())\n",
    "        # Recurrence\n",
    "        # Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "        self.rnn = nn.RNNCell( self.x_dim + self.z_dim + self.y_dim, self.h_dim, bias, nonlinearity='tanh')#nn.GRU( h_dim + x_dim + z_dim + y_dim , h_dim, n_layers)\n",
    "\n",
    "\n",
    "    def encoder(self, x, y, h):\n",
    "        input_enc = torch.cat([x, y, h], 0)\n",
    "        enc = self.enc(input_enc)\n",
    "        enc_mean = self.enc_mean(enc)\n",
    "        enc_std = self.enc_std(enc)\n",
    "        return enc_mean, enc_std\n",
    "    \n",
    "    def decoder(self, z, y, h):\n",
    "        input_dec = torch.cat([z, y, h], 0)\n",
    "        dec = self.dec(input_dec)\n",
    "        dec_mean = self.dec_mean(dec)\n",
    "        dec_std = self.dec_std(dec)\n",
    "        return dec_mean, dec_std\n",
    "    \n",
    "    def get_cost_labeled(self, x, y, h):\n",
    "        # Prior p(z_t | y_t, h_{t-1})\n",
    "        input_pz =  torch.cat([y, h], 0)\n",
    "        prior_zt = self.prior_z(input_pz)\n",
    "        prior_zt_mean = self.prior_z_mean(prior_zt)\n",
    "        prior_zt_std = self.prior_z_std(prior_zt)\n",
    "        # Encoder q(z_t | x_t, y_t, h_{t-1})\n",
    "        enc_mean, enc_std = self.encoder(x, y, h)\n",
    "        z_t = self._reparameterized_sample(enc_mean, enc_std)\n",
    "        # Decoder p(x_t | z_t, y_t, h_{t-1})\n",
    "        dec_mean, dec_std = self.decoder(z_t, y, h)\n",
    "        # Loss\n",
    "        kld_loss_l = self._kld_gauss(enc_mean, enc_std, prior_zt_mean, prior_zt_std)\n",
    "        rec_loss_l = self._rec_gauss(x, dec_mean, dec_std)\n",
    "        \n",
    "        return kld_loss_l, rec_loss_l, z_t\n",
    "\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        h_t = torch.zeros(self.h_dim).to(self.device)\n",
    "        kld_loss_l = 0\n",
    "        rec_loss_l = 0\n",
    "        y_loss_l = 0\n",
    "\n",
    "        kld_loss_u = 0\n",
    "        rec_loss_u = 0\n",
    "        y_loss_u = 0\n",
    "        for t in range(x.size(0)):\n",
    "            # Prior p(y_t | h_{t-1})\n",
    "            p_yt = self.prior_y_proba(self.prior_y(h_t))            \n",
    "            if y[t] != -1:\n",
    "                kld_loss, rec_loss, z_t = self.get_cost_labeled(x[t], y[t], h_t)\n",
    "                kld_loss_l += kld_loss \n",
    "                rec_loss_l += rec_loss\n",
    "                y_loss_l += self._nll_ber(p_yt, y[t])\n",
    "            else:\n",
    "                # q(y_t | x_t, h_{t-1})\n",
    "                q_yt = self.q_y_proba(self.q_y(torch.cat([x[t], h_t], 0)))\n",
    "                # Sample y_t ~ q(y_t | x_t, h_{t-1})\n",
    "                y_t = self._reparameterized_sample_Gumbell(q_yt)\n",
    "                # loss\n",
    "                kld_loss, rec_loss, z_t = self.get_cost_labeled(x[t], y_t, h_t)\n",
    "                kld_loss_u += kld_loss\n",
    "                rec_loss_u += rec_loss\n",
    "                y_loss_u += self._kld_cat(p_yt, q_yt)\n",
    "            # Recurrent h_t = f(h_{t-1}, y_t, z_t, x_{t-1})\n",
    "            if t==0:\n",
    "                h_t = self.rnn(torch.cat([y[t], z_t, 0*x[t-1]], 0)[None, :], h_t[None, :]).squeeze(0)\n",
    "            else:\n",
    "                h_t = self.rnn(torch.cat([y[t], z_t, x[t-1]], 0)[None, :], h_t[None, :]).squeeze(0)\n",
    "        return kld_loss_l, rec_loss_l, y_loss_l, kld_loss_u, rec_loss_u, y_loss_u\n",
    "        \n",
    "\n",
    "    def _nll_ber(self, mean, x):\n",
    "        nll_loss = F.binary_cross_entropy(mean, x, reduction='sum')\n",
    "        return nll_loss\n",
    "    \n",
    "    # def _nll_gauss(self, mean, std, x):\n",
    "    #     return torch.sum(torch.log(std + EPS) + torch.log(2*torch.pi)/2 + (x - mean).pow(2)/(2*std.pow(2)))\n",
    "\n",
    "    def _rec_gauss(self, x, mean, std):\n",
    "        rec_loss = torch.sum(c + torch.log(std) + (x - mean)**2 / (2 * std**2))\n",
    "        return rec_loss\n",
    "    \n",
    "    def _kld_gauss(self, mean_1, std_1, mean_2, std_2):\n",
    "        norm_dis2 = Norm.Normal(mean_2, std_2)\n",
    "        norm_dis1 = Norm.Normal(mean_1, std_1)\n",
    "        kl_loss = torch.sum(KL.kl_divergence(norm_dis1, norm_dis2))\n",
    "        return    kl_loss\n",
    "    \n",
    "    def _kld_cat(self, q, p):\n",
    "        kl_loss = torch.sum(q * torch.log(q/p)+ (1-q) * torch.log((1-q)/(1-p)))\n",
    "        return kl_loss\n",
    "    \n",
    "    def reset_parameters(self, stdv = 0.1):\n",
    "        for weight in self.parameters():\n",
    "            weight.normal_(0, stdv)\n",
    "            #weight.data.normal_(0, stdv)\n",
    "            \n",
    "    # Extra functions \n",
    "    def _init_weights(self, stdv):\n",
    "        pass\n",
    "    \n",
    "    def _reparameterized_sample(self, mean, std):\n",
    "        \"\"\"using std to sample\"\"\"\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        #eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mean)\n",
    "    \n",
    "    def _reparameterized_sample_Gumbell(self, mean):\n",
    "        \"\"\"using std to sample\"\"\"\n",
    "        #eps = torch.FloatTensor(mean.size()).uniform()\n",
    "        eps = eps = torch.rand(mean.size()) \n",
    "        #eps = Variable(eps)\n",
    "        value = torch.log(eps) - torch.log(1-eps) + torch.log(mean) - torch.log(1-mean)\n",
    "        return self.Soft_threshold(value)\n",
    "    \n",
    "    def sample(self, x, y):\n",
    "        '''\n",
    "        Complete image\n",
    "        '''\n",
    "        h_t = torch.zeros(self.h_dim).to(self.device)\n",
    "        y_complete = y.clone()\n",
    "        for t in range(x.size(0)):          \n",
    "            if y[t] != -1:\n",
    "                enc_mean, enc_std = self.encoder(x[t], y[t], h_t)\n",
    "                z_t = self._reparameterized_sample(enc_mean, enc_std)\n",
    "            else:                \n",
    "                q_yt = self.q_y_proba(self.q_y(torch.cat([x[t], h_t], 0)))\n",
    "                l_x_t = Bernoulli(q_yt)\n",
    "                y_t = l_x_t.sample() \n",
    "                #print(y_t)\n",
    "                y_complete[t] = y_t.item()                \n",
    "                enc_mean, enc_std = self.encoder(x[t], y[t], h_t)\n",
    "                z_t = self._reparameterized_sample(enc_mean, enc_std)\n",
    "                \n",
    "            if t==0:\n",
    "                h_t = self.rnn(torch.cat([y[t], z_t, 0*x[t-1]], 0)[None, :], h_t[None, :]).squeeze(0)\n",
    "            else:\n",
    "                h_t = self.rnn(torch.cat([y[t], z_t, x[t-1]], 0)[None, :], h_t[None, :]).squeeze(0)\n",
    "        return y_complete\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqModel(x_dim, z_dim, h_dim, n_layers, y_dim, device, n_samples)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay_)\n",
    "# print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 28\n",
    "idx = 1520\n",
    "x  = x_y_train[idx][0].reshape(size*size, 1)\n",
    "y = x_y_train[idx][1].reshape(size*size, 1)\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_seq(x, y,model,optimizer,clip, path_save_model, n_epochs , device,save_every=5):\n",
    "    train_LOSS = []\n",
    "    path_save = os.path.join(path_save_model, model.__class__.__name__.casefold() +'_state_')\n",
    "    print('The model is saved in this path', os.path.join(path_save_model, model.__class__.__name__.casefold()))\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        #training \n",
    "        kld_loss_l, rec_loss_l, y_loss_l, kld_loss_u, rec_loss_u, y_loss_u = model(x,y)\n",
    "        loss_l = kld_loss_l + rec_loss_l + y_loss_l\n",
    "        loss_u = kld_loss_u + rec_loss_u + y_loss_u        \n",
    "        loss = loss_l + loss_u\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        train_LOSS.append(loss.item())\n",
    "        #saving model\n",
    "        if epoch % save_every == 0:\n",
    "            print('Loss Labeled: {:.6f} \\t Loss Unlabeled: {:.6f}'.format(\n",
    "                    loss_l.item(), loss_u.item()))     \n",
    "            # print('\\n kdl_loss_l: {:.4f} \\t rec_loss_l: {:.4f} \\t y_loss_l: {:.4f}'.format(kld_loss_l.item(), rec_loss_l.item(), y_loss_l.item()))\n",
    "            # print('\\n kdl_loss_u: {:.4f} \\t rec_loss_u: {:.4f} \\t y_loss_u: {:.4f}'.format(kld_loss_u.item(), rec_loss_u.item(), y_loss_u.item()))\n",
    "            fn = path_save+str(epoch)+'.pth'\n",
    "            torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss.item(),\n",
    "                        }, fn)\n",
    "            #torch.save(model.state_dict(), fn)\n",
    "            # print('Saved model to '+fn)\n",
    "            np.save(path_save+'train_'+str(epoch)+'.npy', train_LOSS)     \n",
    "    return train_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved in this path C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\mnist\\seqmodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-448-7a8b06f81398>:12: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Labeled: -442.004211 \t Loss Unlabeled: -391.683624\n",
      "Loss Labeled: -486.769592 \t Loss Unlabeled: -386.897034\n",
      "Loss Labeled: -510.642212 \t Loss Unlabeled: -394.558685\n",
      "Loss Labeled: -539.694458 \t Loss Unlabeled: -408.817200\n",
      "Loss Labeled: -580.172241 \t Loss Unlabeled: -387.373535\n",
      "Loss Labeled: -619.223267 \t Loss Unlabeled: -380.237610\n",
      "Loss Labeled: -640.079956 \t Loss Unlabeled: -380.742432\n",
      "Loss Labeled: -646.418457 \t Loss Unlabeled: -411.804321\n",
      "Loss Labeled: -659.017578 \t Loss Unlabeled: -435.564240\n",
      "Loss Labeled: -666.295044 \t Loss Unlabeled: -428.880219\n",
      "Loss Labeled: -667.960205 \t Loss Unlabeled: -448.443756\n",
      "Loss Labeled: -672.292908 \t Loss Unlabeled: -410.919891\n",
      "Loss Labeled: -668.016602 \t Loss Unlabeled: -445.140411\n",
      "Loss Labeled: -680.937866 \t Loss Unlabeled: -448.449188\n",
      "Loss Labeled: -677.561890 \t Loss Unlabeled: -440.298309\n",
      "Loss Labeled: -686.622192 \t Loss Unlabeled: -433.543701\n",
      "Loss Labeled: -681.107788 \t Loss Unlabeled: -414.163910\n",
      "Loss Labeled: -682.037842 \t Loss Unlabeled: -447.596375\n",
      "Loss Labeled: -694.365540 \t Loss Unlabeled: -438.998260\n",
      "Loss Labeled: -683.742798 \t Loss Unlabeled: -428.354065\n"
     ]
    }
   ],
   "source": [
    "loss = run_model_seq(x, y,model,optimizer,clip, path_save, n_epochs , device,save_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(model, optimizer, epoch_model, path_save, data,print_loss =True):\n",
    "    print('Actual  path for to initialize our models: ', path_save)\n",
    "    path = os.path.join(path_save, model.__class__.__name__.casefold()+'_state_'+str(epoch_model)+'.pth') \n",
    "    print(path)\n",
    "    checkpoint = torch.load(path)\n",
    "    print(f'Initialization of the {model.__class__.__name__} model  at epoch {epoch_model}')\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    if print_loss:\n",
    "        print(f'loss: {loss} and epoch: {epoch}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual  path for to initialize our models:  C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\mnist\n",
      "C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\mnist\\seqmodel_state_100.pth\n",
      "Initialization of the SeqModel model  at epoch 100\n",
      "loss: -1112.096923828125 and epoch: 100\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------\n",
    "model = SeqModel(x_dim, z_dim, h_dim, n_layers, y_dim, device, n_samples)\n",
    "epoch_model = 100\n",
    "#-----------------------------------------------------\n",
    "model = final_model(model, optimizer, epoch_model, path_save, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_noisy_image(img, mu, sigma,p,  size = 28, complex = False):\n",
    "    '''\n",
    "    image: image of size 28*28\n",
    "    Binary mask: 0 if the pixel is the background, 1 otherwise (part of the number)\n",
    "    \n",
    "    chain: chain of the image (Hilbert curve) which is a vector of size size*size \n",
    "    z =  N(0, 1) # random variable wich\n",
    "    x = z* N(mu, sigma)\n",
    "\n",
    "    return:\n",
    "    image_x: image with noise (28*28)\n",
    "    label_miss: input image with missing labels (28*28)\n",
    "    '''\n",
    "    # We use np.pad to add a border of 0 to the image and increase the size to 32*32 beacause:\n",
    "    # 1D sequence <-> image, using an hilbert curve requires the sequence have length equal to a --power of 2--    \n",
    "    # This is not a general solution, but it works for the MNIST dataset\n",
    "    image = np.pad(img.reshape(size, size), ((2,2), (2,2)), 'constant')\n",
    "    chain = image_to_chain(image)\n",
    "    # More complex noisy image\n",
    "    # mu*(chain[i]) is the mean of the normal distribution and it changes for each pixel with respect to the label at that pixel\n",
    "    if complex:\n",
    "        z = np.random.normal(size = len(chain))\n",
    "        x = np.array([  z[i]*np.random.normal(mu*(chain[i]), sigma, 1) for i in range(len(chain)) ])\n",
    "    else:\n",
    "        x = np.array([np.random.normal(mu*(chain[i]), sigma, 1) for i in range(len(chain)) ])\n",
    "    \n",
    "     # In order to recuperate the original image we need to remove the first 2 and last 2 elements of the chain\n",
    "    image_x = chain_to_image(x)[2:(2+size), 2:(2+size)]\n",
    "    mask_missing = np.random.choice([0,1], size=(size, size), p=[p, 1-p])\n",
    "    label_miss = img.reshape(size, size).copy()\n",
    "    label_miss[mask_missing==0] = -1\n",
    "    return [image_x, label_miss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_ = model.sample(x,y)\n",
    "image_complete = y_.detach().numpy().reshape(28,28)\n",
    "image_complete[size-1,size-1] = -1\n",
    "image_labeled = trainX[idx].reshape(28,28)\n",
    "image_labeled[size-1,size-1] = -1\n",
    "plt.imshow(x.detach().numpy().reshape(28,28))\n",
    "plt.show()\n",
    "plt.imshow(image_complete)\n",
    "plt.show()\n",
    "plt.imshow(image_labeled)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(y.detach().numpy().reshape(28,28))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-532-2489bd117577>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x1 = torch.tensor(x1, dtype=torch.float32)\n",
      "<ipython-input-532-2489bd117577>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y1 = torch.tensor(y1, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 0.65\n",
    "complex = True\n",
    "size = 28\n",
    "idx = 480\n",
    "x1, y1 = creation_noisy_image(trainX[idx], mu, sigma,p,  size = 28, complex = complex)\n",
    "x1 = torch.tensor(x1.reshape(size*size, 1), dtype=torch.float32)\n",
    "y1 = torch.tensor(y1.reshape(size*size, 1), dtype=torch.float32)\n",
    "\n",
    "x1 = torch.tensor(x1, dtype=torch.float32)\n",
    "y1 = torch.tensor(y1, dtype=torch.float32)\n",
    "\n",
    "y1_ = model.sample(x1,y1)\n",
    "image_complete = y1_.detach().numpy().reshape(28,28)\n",
    "image_labeled = trainX[idx].reshape(28,28)\n",
    "image_labeled[size-1,size-1] = -1\n",
    "image_complete[size-1,size-1] = -1\n",
    "plt.imshow(x1.detach().numpy().reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(image_complete, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(image_labeled, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(y1.detach().numpy().reshape(28,28), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Models\n",
    "based on https://github.com/emited/VariationalRecurrentNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 128, 28])\n",
      "torch.Size([28, 128, 28])\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# img = True images of 28*28 (generative model)\n",
    "# img = False  images of 1*784 (seq case)\n",
    "img = True\n",
    "if img:\n",
    "    trainX = dim_image(trainX)\n",
    "    testX = dim_image(testX)\n",
    "\n",
    "batch_sz = 128\n",
    "\n",
    "train_loader, test_loader = analysis(trainX,testX,batch_sz)\n",
    "train_loader_elbo, test_loader_elbo = analysis(trainX,testX,1)\n",
    "\n",
    "for batch_idx, data_s in enumerate(train_loader):\n",
    "    if batch_idx <2:\n",
    "        data_s = data_s.to(device)\n",
    "        data_s = data_s.float()\n",
    "        if img:\n",
    "            data_s = data_s.transpose(0, 1)\n",
    "        else:\n",
    "            data_s = data_s.transpose(0, 1).unsqueeze(2)\n",
    "        print(data_s.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "music = True\n",
    "if music:\n",
    "    x_dim = 88    \n",
    "else:\n",
    "    x_dim = 1\n",
    "\n",
    "# Dimension of latent variables\n",
    "z_dim = 300\n",
    "px_dim = 100\n",
    "pz_dim = 100\n",
    "qz_dim = 500 \n",
    "h_dim_vrnn = 300 #initial h_dim for VRNN for the next models this values will be changed\n",
    "\n",
    "# Model settings\n",
    "learning_rate = 0.003  #0.001\n",
    "weight_decay_ = 1e-4\n",
    "n_samples = 100\n",
    "n_layers =  1\n",
    "n_epochs = 100\n",
    "clip = 10\n",
    "#--------------------------------------------\n",
    "# Manual seed\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "#--------------------------------------------\n",
    "# Print settings\n",
    "print_every = 100\n",
    "#--------------------------------------------\n",
    "# Save models\n",
    "save_every = 5\n",
    "path_save = os.path.join(general_path, data)\n",
    "print(f'Actual path to save our models for {data} is {path_save} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Identity: 1-1                          --\n",
      "├─Identity: 1-2                          --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-1                       42,500\n",
      "|    └─ReLU: 2-2                         --\n",
      "├─Linear: 1-4                            42,824\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-3                       42,824\n",
      "|    └─Softplus: 2-4                     --\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─Linear: 2-5                       256,500\n",
      "|    └─ReLU: 2-6                         --\n",
      "├─Linear: 1-7                            212,424\n",
      "├─Sequential: 1-8                        --\n",
      "|    └─Linear: 2-7                       212,424\n",
      "|    └─Softplus: 2-8                     --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-9                       42,500\n",
      "|    └─ReLU: 2-10                        --\n",
      "├─Sequential: 1-10                       --\n",
      "|    └─Linear: 2-11                      8,888\n",
      "|    └─Sigmoid: 2-12                     --\n",
      "├─Sequential: 1-11                       --\n",
      "|    └─Linear: 2-13                      8,888\n",
      "|    └─Softmax: 2-14                     --\n",
      "=================================================================\n",
      "Total params: 869,772\n",
      "Trainable params: 869,772\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Identity: 1-1                          --\n",
      "├─Identity: 1-2                          --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-1                       42,500\n",
      "|    └─ReLU: 2-2                         --\n",
      "├─Linear: 1-4                            42,824\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-3                       42,824\n",
      "|    └─Softplus: 2-4                     --\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─Linear: 2-5                       256,500\n",
      "|    └─ReLU: 2-6                         --\n",
      "├─Linear: 1-7                            212,424\n",
      "├─Sequential: 1-8                        --\n",
      "|    └─Linear: 2-7                       212,424\n",
      "|    └─Softplus: 2-8                     --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-9                       42,500\n",
      "|    └─ReLU: 2-10                        --\n",
      "├─Sequential: 1-10                       --\n",
      "|    └─Linear: 2-11                      8,888\n",
      "|    └─Sigmoid: 2-12                     --\n",
      "├─Sequential: 1-11                       --\n",
      "|    └─Linear: 2-13                      8,888\n",
      "|    └─Softmax: 2-14                     --\n",
      "=================================================================\n",
      "Total params: 869,772\n",
      "Trainable params: 869,772\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "z_dim = 424\n",
    "learning_rate = 0.005  #only for HMM model\n",
    "#--------------------------------------------\n",
    "# Model\n",
    "model = HMM(x_dim, z_dim, px_dim, pz_dim, qz_dim, n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay_)\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved in this path C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmorales\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "c:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\utils\\utils.py:29: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/272 (0%)]\t KLD Loss: 4002.454834 \t NLL Loss: 6196.631836\n",
      "\n",
      "Train> Epoch: 1 average -ELBO: 4155.5080\n",
      "====> Test set loss: -ELBO 1337.7329, KLD Loss = 105.3312, NLL Loss = 1232.4018 \n",
      "Train Epoch: 2 [0/272 (0%)]\t KLD Loss: 103.397324 \t NLL Loss: 1288.330322\n",
      "\n",
      "Train> Epoch: 2 average -ELBO: 1262.4395\n",
      "====> Test set loss: -ELBO 1176.5438, KLD Loss = 17.2943, NLL Loss = 1159.2496 \n",
      "Train Epoch: 3 [0/272 (0%)]\t KLD Loss: 17.534153 \t NLL Loss: 1177.902222\n",
      "\n",
      "Train> Epoch: 3 average -ELBO: 1165.9901\n",
      "====> Test set loss: -ELBO 1136.1891, KLD Loss = 8.7617, NLL Loss = 1127.4274 \n",
      "Train Epoch: 4 [0/272 (0%)]\t KLD Loss: 9.842326 \t NLL Loss: 1145.813965\n",
      "\n",
      "Train> Epoch: 4 average -ELBO: 1142.0048\n",
      "====> Test set loss: -ELBO 1126.3244, KLD Loss = 7.5954, NLL Loss = 1118.7290 \n",
      "Train Epoch: 5 [0/272 (0%)]\t KLD Loss: 8.988995 \t NLL Loss: 1139.162476\n",
      "\n",
      "Train> Epoch: 5 average -ELBO: 1134.0994\n",
      "====> Test set loss: -ELBO 1114.2999, KLD Loss = 10.3206, NLL Loss = 1103.9793 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_5.pth\n",
      "Train Epoch: 6 [0/272 (0%)]\t KLD Loss: 11.914947 \t NLL Loss: 1120.157227\n",
      "\n",
      "Train> Epoch: 6 average -ELBO: 1126.5683\n",
      "====> Test set loss: -ELBO 1104.7138, KLD Loss = 19.2834, NLL Loss = 1085.4304 \n",
      "Train Epoch: 7 [0/272 (0%)]\t KLD Loss: 21.558914 \t NLL Loss: 1101.209961\n",
      "\n",
      "Train> Epoch: 7 average -ELBO: 1112.1432\n",
      "====> Test set loss: -ELBO 1089.2839, KLD Loss = 35.8942, NLL Loss = 1053.3897 \n",
      "Train Epoch: 8 [0/272 (0%)]\t KLD Loss: 38.647762 \t NLL Loss: 1067.494141\n",
      "\n",
      "Train> Epoch: 8 average -ELBO: 1100.7838\n",
      "====> Test set loss: -ELBO 1080.4402, KLD Loss = 40.9752, NLL Loss = 1039.4650 \n",
      "Train Epoch: 9 [0/272 (0%)]\t KLD Loss: 43.678265 \t NLL Loss: 1055.326538\n",
      "\n",
      "Train> Epoch: 9 average -ELBO: 1094.9438\n",
      "====> Test set loss: -ELBO 1071.8993, KLD Loss = 40.1951, NLL Loss = 1031.7042 \n",
      "Train Epoch: 10 [0/272 (0%)]\t KLD Loss: 40.981529 \t NLL Loss: 1047.822266\n",
      "\n",
      "Train> Epoch: 10 average -ELBO: 1087.2335\n",
      "====> Test set loss: -ELBO 1071.8932, KLD Loss = 38.3064, NLL Loss = 1033.5868 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_10.pth\n",
      "Train Epoch: 11 [0/272 (0%)]\t KLD Loss: 40.574635 \t NLL Loss: 1052.782104\n",
      "\n",
      "Train> Epoch: 11 average -ELBO: 1085.9835\n",
      "====> Test set loss: -ELBO 1067.2171, KLD Loss = 40.8340, NLL Loss = 1026.3832 \n",
      "Train Epoch: 12 [0/272 (0%)]\t KLD Loss: 42.017925 \t NLL Loss: 1044.166504\n",
      "\n",
      "Train> Epoch: 12 average -ELBO: 1082.1966\n",
      "====> Test set loss: -ELBO 1065.0667, KLD Loss = 40.6469, NLL Loss = 1024.4197 \n",
      "Train Epoch: 13 [0/272 (0%)]\t KLD Loss: 39.145226 \t NLL Loss: 1039.139160\n",
      "\n",
      "Train> Epoch: 13 average -ELBO: 1081.9311\n",
      "====> Test set loss: -ELBO 1063.5261, KLD Loss = 42.2523, NLL Loss = 1021.2738 \n",
      "Train Epoch: 14 [0/272 (0%)]\t KLD Loss: 42.316757 \t NLL Loss: 1035.984009\n",
      "\n",
      "Train> Epoch: 14 average -ELBO: 1077.3225\n",
      "====> Test set loss: -ELBO 1058.5552, KLD Loss = 42.0662, NLL Loss = 1016.4891 \n",
      "Train Epoch: 15 [0/272 (0%)]\t KLD Loss: 43.018009 \t NLL Loss: 1034.730957\n",
      "\n",
      "Train> Epoch: 15 average -ELBO: 1076.0686\n",
      "====> Test set loss: -ELBO 1056.8036, KLD Loss = 43.4864, NLL Loss = 1013.3171 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_15.pth\n",
      "Train Epoch: 16 [0/272 (0%)]\t KLD Loss: 42.167534 \t NLL Loss: 1030.464355\n",
      "\n",
      "Train> Epoch: 16 average -ELBO: 1074.4918\n",
      "====> Test set loss: -ELBO 1052.0894, KLD Loss = 49.2491, NLL Loss = 1002.8404 \n",
      "Train Epoch: 17 [0/272 (0%)]\t KLD Loss: 48.753166 \t NLL Loss: 1024.201904\n",
      "\n",
      "Train> Epoch: 17 average -ELBO: 1070.1612\n",
      "====> Test set loss: -ELBO 1045.1761, KLD Loss = 54.3905, NLL Loss = 990.7855 \n",
      "Train Epoch: 18 [0/272 (0%)]\t KLD Loss: 52.946400 \t NLL Loss: 1014.561890\n",
      "\n",
      "Train> Epoch: 18 average -ELBO: 1062.5822\n",
      "====> Test set loss: -ELBO 1034.5127, KLD Loss = 62.8338, NLL Loss = 971.6789 \n",
      "Train Epoch: 19 [0/272 (0%)]\t KLD Loss: 62.878231 \t NLL Loss: 1001.753784\n",
      "\n",
      "Train> Epoch: 19 average -ELBO: 1057.1393\n",
      "====> Test set loss: -ELBO 1029.2191, KLD Loss = 73.2887, NLL Loss = 955.9304 \n",
      "Train Epoch: 20 [0/272 (0%)]\t KLD Loss: 70.641800 \t NLL Loss: 978.595947\n",
      "\n",
      "Train> Epoch: 20 average -ELBO: 1049.0020\n",
      "====> Test set loss: -ELBO 1024.8349, KLD Loss = 79.9103, NLL Loss = 944.9246 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_20.pth\n",
      "Train Epoch: 21 [0/272 (0%)]\t KLD Loss: 77.608490 \t NLL Loss: 968.982239\n",
      "\n",
      "Train> Epoch: 21 average -ELBO: 1044.3203\n",
      "====> Test set loss: -ELBO 1020.7487, KLD Loss = 82.6967, NLL Loss = 938.0520 \n",
      "Train Epoch: 22 [0/272 (0%)]\t KLD Loss: 80.344666 \t NLL Loss: 963.237000\n",
      "\n",
      "Train> Epoch: 22 average -ELBO: 1039.3654\n",
      "====> Test set loss: -ELBO 1011.6403, KLD Loss = 90.1185, NLL Loss = 921.5219 \n",
      "Train Epoch: 23 [0/272 (0%)]\t KLD Loss: 87.481529 \t NLL Loss: 943.489319\n",
      "\n",
      "Train> Epoch: 23 average -ELBO: 1032.3633\n",
      "====> Test set loss: -ELBO 1011.0715, KLD Loss = 96.4539, NLL Loss = 914.6176 \n",
      "Train Epoch: 24 [0/272 (0%)]\t KLD Loss: 93.479813 \t NLL Loss: 935.238281\n",
      "\n",
      "Train> Epoch: 24 average -ELBO: 1025.3440\n",
      "====> Test set loss: -ELBO 999.8766, KLD Loss = 104.7066, NLL Loss = 895.1699 \n",
      "Train Epoch: 25 [0/272 (0%)]\t KLD Loss: 106.059425 \t NLL Loss: 924.265564\n",
      "\n",
      "Train> Epoch: 25 average -ELBO: 1018.1489\n",
      "====> Test set loss: -ELBO 995.7669, KLD Loss = 113.0829, NLL Loss = 882.6840 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_25.pth\n",
      "Train Epoch: 26 [0/272 (0%)]\t KLD Loss: 112.688049 \t NLL Loss: 912.724243\n",
      "\n",
      "Train> Epoch: 26 average -ELBO: 1012.3327\n",
      "====> Test set loss: -ELBO 990.7116, KLD Loss = 108.5329, NLL Loss = 882.1787 \n",
      "Train Epoch: 27 [0/272 (0%)]\t KLD Loss: 107.905678 \t NLL Loss: 904.651917\n",
      "\n",
      "Train> Epoch: 27 average -ELBO: 1009.2120\n",
      "====> Test set loss: -ELBO 989.0532, KLD Loss = 112.0852, NLL Loss = 876.9680 \n",
      "Train Epoch: 28 [0/272 (0%)]\t KLD Loss: 113.317139 \t NLL Loss: 897.454834\n",
      "\n",
      "Train> Epoch: 28 average -ELBO: 1005.8514\n",
      "====> Test set loss: -ELBO 988.8102, KLD Loss = 111.5699, NLL Loss = 877.2404 \n",
      "Train Epoch: 29 [0/272 (0%)]\t KLD Loss: 110.190422 \t NLL Loss: 897.750610\n",
      "\n",
      "Train> Epoch: 29 average -ELBO: 1005.4340\n",
      "====> Test set loss: -ELBO 988.8924, KLD Loss = 118.7095, NLL Loss = 870.1829 \n",
      "Train Epoch: 30 [0/272 (0%)]\t KLD Loss: 121.756332 \t NLL Loss: 891.826904\n",
      "\n",
      "Train> Epoch: 30 average -ELBO: 1004.4292\n",
      "====> Test set loss: -ELBO 985.7623, KLD Loss = 116.8768, NLL Loss = 868.8855 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_30.pth\n",
      "Train Epoch: 31 [0/272 (0%)]\t KLD Loss: 116.396454 \t NLL Loss: 886.243835\n",
      "\n",
      "Train> Epoch: 31 average -ELBO: 1002.5551\n",
      "====> Test set loss: -ELBO 986.1242, KLD Loss = 119.8520, NLL Loss = 866.2723 \n",
      "Train Epoch: 32 [0/272 (0%)]\t KLD Loss: 123.308060 \t NLL Loss: 894.575012\n",
      "\n",
      "Train> Epoch: 32 average -ELBO: 1005.2936\n",
      "====> Test set loss: -ELBO 980.8708, KLD Loss = 121.4406, NLL Loss = 859.4301 \n",
      "Train Epoch: 33 [0/272 (0%)]\t KLD Loss: 121.804626 \t NLL Loss: 879.693481\n",
      "\n",
      "Train> Epoch: 33 average -ELBO: 1001.0599\n",
      "====> Test set loss: -ELBO 985.4949, KLD Loss = 120.2413, NLL Loss = 865.2536 \n",
      "Train Epoch: 34 [0/272 (0%)]\t KLD Loss: 123.894798 \t NLL Loss: 884.158142\n",
      "\n",
      "Train> Epoch: 34 average -ELBO: 1001.7105\n",
      "====> Test set loss: -ELBO 981.5996, KLD Loss = 119.2642, NLL Loss = 862.3354 \n",
      "Train Epoch: 35 [0/272 (0%)]\t KLD Loss: 123.258110 \t NLL Loss: 884.334717\n",
      "\n",
      "Train> Epoch: 35 average -ELBO: 998.5201\n",
      "====> Test set loss: -ELBO 978.2044, KLD Loss = 119.9386, NLL Loss = 858.2658 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_35.pth\n",
      "Train Epoch: 36 [0/272 (0%)]\t KLD Loss: 122.022385 \t NLL Loss: 888.905823\n",
      "\n",
      "Train> Epoch: 36 average -ELBO: 996.8695\n",
      "====> Test set loss: -ELBO 977.1199, KLD Loss = 123.7660, NLL Loss = 853.3539 \n",
      "Train Epoch: 37 [0/272 (0%)]\t KLD Loss: 127.110161 \t NLL Loss: 874.392029\n",
      "\n",
      "Train> Epoch: 37 average -ELBO: 998.6521\n",
      "====> Test set loss: -ELBO 980.3270, KLD Loss = 124.4522, NLL Loss = 855.8748 \n",
      "Train Epoch: 38 [0/272 (0%)]\t KLD Loss: 127.652054 \t NLL Loss: 876.377563\n",
      "\n",
      "Train> Epoch: 38 average -ELBO: 999.9718\n",
      "====> Test set loss: -ELBO 978.2044, KLD Loss = 126.4165, NLL Loss = 851.7879 \n",
      "Train Epoch: 39 [0/272 (0%)]\t KLD Loss: 130.323364 \t NLL Loss: 870.126831\n",
      "\n",
      "Train> Epoch: 39 average -ELBO: 998.3085\n",
      "====> Test set loss: -ELBO 978.8699, KLD Loss = 121.6908, NLL Loss = 857.1791 \n",
      "Train Epoch: 40 [0/272 (0%)]\t KLD Loss: 126.867195 \t NLL Loss: 875.875671\n",
      "\n",
      "Train> Epoch: 40 average -ELBO: 994.9533\n",
      "====> Test set loss: -ELBO 975.1055, KLD Loss = 124.3433, NLL Loss = 850.7622 \n",
      "Saved model to C:\\Users\\kmorales\\Desktop\\3th PhD\\PMM SImulations\\jsb\\hmm_state_40.pth\n",
      "Train Epoch: 41 [0/272 (0%)]\t KLD Loss: 125.978668 \t NLL Loss: 865.084412\n",
      "\n",
      "Train> Epoch: 41 average -ELBO: 995.6790\n",
      "====> Test set loss: -ELBO 978.6182, KLD Loss = 125.1897, NLL Loss = 853.4286 \n",
      "Train Epoch: 42 [0/272 (0%)]\t KLD Loss: 128.022598 \t NLL Loss: 871.957031\n"
     ]
    }
   ],
   "source": [
    "train_LOSS_1, test_LOSS_1 = run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save, n_epochs ,print_every, music, save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #--------------------------------------------\n",
    "# # Copy from this part to the end of the code\n",
    "# #--------------------------------------------\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay_)\n",
    "# print(summary(model))\n",
    "# #-----------------------------------------------------\n",
    "# # Train the model\n",
    "# #-----------------------------------------------------\n",
    "# train_LOSS_2, test_LOSS_2 = run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save, n_epochs ,print_every, music, save_every)\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Initialization of the model\n",
    "#-----------------------------------------------------\n",
    "epoch_model = 100\n",
    "# Last models= True : Epochs saved in 2021\n",
    "model = final_model(model, optimizer, epoch_model, path_save, data, print_loss =True, last_models = False)\n",
    "elb, lpx = ELBO(test_loader_elbo, model, n_samples, path_save, music, save_info= False)\n",
    "print(np.mean(elb))\n",
    "print(np.mean(lpx))\n",
    "# =>i:0, mean ELBO = -2075.6604, App. mean Log = -2016.8858 \n",
    "# =>i:0, ELBO = -2075.6604, App. Log = -2016.8858 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRNN\n",
    "\n",
    "https://github.com/marcofraccaro/srnn\n",
    "\n",
    "https://github.com/clinicalml/structuredinference/blob/master/parse_args_dkf.py\n",
    "\n",
    "https://github.com/jych/nips2015_vrnn/blob/master/models/iamondb/vrnn_gauss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Identity: 1-1                          --\n",
      "├─Identity: 1-2                          --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-1                       30,100\n",
      "|    └─ReLU: 2-2                         --\n",
      "├─Linear: 1-4                            30,300\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-3                       30,300\n",
      "|    └─Softplus: 2-4                     --\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─Linear: 2-5                       194,500\n",
      "|    └─ReLU: 2-6                         --\n",
      "├─Linear: 1-7                            150,300\n",
      "├─Sequential: 1-8                        --\n",
      "|    └─Linear: 2-7                       150,300\n",
      "|    └─Softplus: 2-8                     --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-9                       60,100\n",
      "|    └─ReLU: 2-10                        --\n",
      "├─Sequential: 1-10                       --\n",
      "|    └─Linear: 2-11                      8,888\n",
      "|    └─Sigmoid: 2-12                     --\n",
      "├─Sequential: 1-11                       --\n",
      "|    └─Linear: 2-13                      8,888\n",
      "|    └─Softmax: 2-14                     --\n",
      "├─RNNCell: 1-12                          206,400\n",
      "=================================================================\n",
      "Total params: 870,076\n",
      "Trainable params: 870,076\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Identity: 1-1                          --\n",
      "├─Identity: 1-2                          --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-1                       30,100\n",
      "|    └─ReLU: 2-2                         --\n",
      "├─Linear: 1-4                            30,300\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─Linear: 2-3                       30,300\n",
      "|    └─Softplus: 2-4                     --\n",
      "├─Sequential: 1-6                        --\n",
      "|    └─Linear: 2-5                       194,500\n",
      "|    └─ReLU: 2-6                         --\n",
      "├─Linear: 1-7                            150,300\n",
      "├─Sequential: 1-8                        --\n",
      "|    └─Linear: 2-7                       150,300\n",
      "|    └─Softplus: 2-8                     --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-9                       60,100\n",
      "|    └─ReLU: 2-10                        --\n",
      "├─Sequential: 1-10                       --\n",
      "|    └─Linear: 2-11                      8,888\n",
      "|    └─Sigmoid: 2-12                     --\n",
      "├─Sequential: 1-11                       --\n",
      "|    └─Linear: 2-13                      8,888\n",
      "|    └─Softmax: 2-14                     --\n",
      "├─RNNCell: 1-12                          206,400\n",
      "=================================================================\n",
      "Total params: 870,076\n",
      "Trainable params: 870,076\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "h_dim = h_dim_vrnn\n",
    "#--------------------------------------------\n",
    "# Model\n",
    "model = VRNN(x_dim, h_dim, z_dim, px_dim, pz_dim, qz_dim, n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay_)\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_LOSS_1, test_LOSS_1 = run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save, n_epochs ,print_every, music, save_every)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of a trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "model = VRNN(x_dim, h_dim, z_dim, px_dim, pz_dim, qz_dim, n_layers).to(device)\n",
    "epoch_model = 100\n",
    "# Last models= True : Epochs saved in 2021\n",
    "#-----------------------------------------------------\n",
    "model = final_model(model, optimizer, epoch_model, path_save, data, print_loss =True, last_models = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # We can continue training\n",
    "# train_LOSS_1, test_LOSS_1 = run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save, n_epochs ,print_every, music, save_every)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO approximation\n",
    "We use the test data set and the final model, so the previous step is important\n",
    "\n",
    "```model = final_model(model, optimizer, epoch_model, path_save, data, print_loss =True, last_models = True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elb, lpx = ELBO(test_loader_elbo, model, n_samples, path_save, music, save_info= False)\n",
    "print(np.mean(elb))\n",
    "print(np.mean(lpx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCM\n",
    "### Calculation of h_dim\n",
    "We calculate this value in order to have a 'similar' number of parameter for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'PCM'\n",
    "number_parameters(name_model, h_dim_vrnn, pz_dim, px_dim, qz_dim ,x_dim, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 294\n",
    "#--------------------------------------------\n",
    "# Model\n",
    "model = PCM(x_dim, h_dim, z_dim,px_dim, pz_dim, qz_dim, n_layers).to(device)\n",
    "#--------------------------------------------\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# Copy from this part to the end of the code\n",
    "#--------------------------------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay_)\n",
    "print(summary(model))\n",
    "# #-----------------------------------------------------\n",
    "# # Train the model\n",
    "# #-----------------------------------------------------\n",
    "# train_LOSS_2, test_LOSS_2 = run_model(train_loader,test_loader,model,optimizer,batch_sz,clip, path_save, n_epochs ,print_every, music, save_every)\n",
    "\n",
    "# #-----------------------------------------------------\n",
    "# # Initialization of the model\n",
    "# #-----------------------------------------------------\n",
    "# epoch_model = 100\n",
    "# # Last models= True : Epochs saved in 2021\n",
    "# model = final_model(model, optimizer, epoch_model, path_save, data, print_loss =True, last_models = True)\n",
    "# elb, lpx = ELBO(test_loader_elbo, model, n_samples, path_save, music, save_info= False)\n",
    "# print(np.mean(elb))\n",
    "# print(np.mean(lpx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCM_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'PCM_c'\n",
    "number_parameters(name_model, h_dim_vrnn, pz_dim, px_dim, qz_dim ,x_dim, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H dim\n",
    "h_dim = 278\n",
    "#--------------------------------------------\n",
    "# Model\n",
    "model = PCM_c(x_dim, h_dim, z_dim,px_dim, pz_dim, qz_dim, n_layers).to(device)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCM_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'PMC_c2'\n",
    "number_parameters(name_model, h_dim_vrnn, pz_dim, px_dim, qz_dim ,x_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H dim\n",
    "h_dim = 260\n",
    "#--------------------------------------------\n",
    "# Model\n",
    "model = PCM_c2(x_dim, h_dim, z_dim,px_dim, pz_dim, qz_dim, n_layers).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad1b2571548246114fecf39d36c90373949ef600ffd6c7010bad9bfc5901cee0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
